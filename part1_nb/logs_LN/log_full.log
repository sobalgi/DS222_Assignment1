[nltk_data] Downloading package stopwords to
[nltk_data]     /home/sourabhbalgi/nltk_data...
[nltk_data]   Package stopwords is already up-to-date!
[nltk_data] Downloading package punkt to
[nltk_data]     /home/sourabhbalgi/nltk_data...
[nltk_data]   Package punkt is already up-to-date!

Extracting data from  "../../../ds222/assignment-1/DBPedia.full/full_train.txt" ...

Total number of training documents : 214994

Shape of one-hot-encoded labels : (214994, 50)

List of classes : ['American_comedy_films' 'American_drama_films' 'American_film_actresses'
 'American_film_directors' 'American_films' 'American_male_film_actors'
 'American_male_television_actors'
 'American_military_personnel_of_World_War_II'
 'American_people_of_Irish_descent' 'American_television_actresses'
 'Arctiidae' 'Articles_containing_video_clips'
 'Association_football_defenders' 'Association_football_forwards'
 'Association_football_goalkeepers' 'Association_football_midfielders'
 'Asteroids_named_for_people'
 'Australian_rules_footballers_from_Victoria_(Australia)'
 'Black-and-white_films' 'Brazilian_footballers' 'British_films'
 'Columbia_University_alumni' 'Deaths_from_myocardial_infarction'
 'English-language_albums' 'English-language_films'
 'English-language_journals' 'English-language_television_programming'
 'English_cricketers' 'English_footballers' 'Fellows_of_the_Royal_Society'
 'French_films' 'German_footballers' 'Guggenheim_Fellows'
 'Harvard_University_alumni' 'Hindi-language_films' 'Indian_films'
 'Insects_of_Europe' 'Italian_films' 'Italian_footballers'
 'Main_Belt_asteroids' 'Major_League_Baseball_pitchers'
 'Rivers_of_Romania' 'Russian_footballers' 'Scottish_footballers'
 'Serie_A_players' 'The_Football_League_players' 'Villages_in_Turkey'
 'Villages_in_the_Czech_Republic' 'Windows_games' 'Yale_University_alumni']

Total number of classes : 50

Creating Mappings for labels ...

Calculating prior probabilities ...

Log prior probabilities of classes : [-4.62746104 -4.43185365 -3.83623286 -4.49320118 -2.92959529 -3.52076537
 -3.7028375  -4.08603836 -4.35220149 -4.00022507 -6.23895869 -4.02732901
 -3.48972917 -3.49789698 -4.08006938 -3.3247235  -4.00665596 -4.64475653
 -3.14760388 -4.42566864 -4.08843596 -4.3944894  -4.26832    -3.8175983
 -2.57627856 -4.67450376 -4.03754283 -4.66591387 -3.20910724 -4.31664332
 -4.65316583 -4.78378601 -4.01591528 -3.6548963  -4.68971593 -3.85633089
 -4.86563468 -4.86389554 -4.57534504 -3.19173984 -3.78842769 -3.53965221
 -4.21198675 -4.41175247 -4.42931879 -3.06621676 -7.82630564 -4.00371099
 -4.09667142 -4.49710684]

Preprocessing (stemming, stopword removal, tokenization) train data ...

Creating mappings for vocabulary ...

Length of vocabulary : 187163

Big-doc creation for each class to find word counts ...
Number of model parameters for full dataset = 757253.
4.0 minutes, 46 seconds for complete training of full dataset.

Saved "final_full_wordclass_counts.json"

Saved "final_full_mappings.json"

Calculating accuracy on training data ...

Training Accuracy on full dataset : 0.8442700726531903

Saved predicted labels for training data in "final_full_trn_pred_labels.txt"
19.0 minutes, 42 seconds for complete training inference of full dataset.

Extracting data from development set ...

Total number of development documents : 61494

Preprocessing (stemming, stopword removal, tokenization) development data ...

Development Accuracy on full dataset : 0.7245584935115621

Saved predicted labels for development data in "final_full_dev_pred_labels.txt"
5.0 minutes, 26 seconds for complete development inference of full dataset.

Extracting data from test set ...

Total number of testing documents : 29994

Preprocessing (stemming, stopword removal, tokenization) test data ...

Test Accuracy on full dataset : 0.73541374941655

Saved predicted labels for test data in "final_full_tst_pred_labels.txt"
2.0 minutes, 13 seconds for complete test inference of full dataset.
Train  Development      Test
0.84427     0.724558  0.735414

Saved model accuracies for full in "final_full_20180912203750_accuracy.log"
32.0 minutes, 8 seconds for complete run of full dataset.
